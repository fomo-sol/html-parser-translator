{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eef47a6",
   "metadata": {},
   "source": [
    "step 2 : translate.ipynb (NLLB 번역 파트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. 번역 파이프라인 준비\n",
    "translator = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46727156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 원본 텍스트 로드\n",
    "with open(\"data/segments/AAPL_2023_Q3_joined.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    original_text = f.read()\n",
    "\n",
    "# 3. 특수 구분자 보호 (␟ → __SEP__)\n",
    "#    \\n\\n␟\\n\\n 형태로 정리된 경우 줄바꿈도 함께 유지\n",
    "protected_text = original_text.replace(\"\\n\\n␟\\n\\n\", \"\\n\\n__SEP__\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d767d177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aapl-20230701\\n\\n__SEP__\\n\\nUNITED STATES\\n\\n__SEP__\\n\\nSECURITIES AND EXCHANGE COMMISSION\\n\\n__SEP__\\n\\nWashington, D.C. 20549\\n\\n__SEP__\\n\\nFORM 10-Q\\n\\n__SEP__\\n\\n(Mark One)\\n\\n__SEP__\\n\\nQUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\n\\n__SEP__\\n\\nor\\n\\n__SEP__\\n\\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\n\\n__SEP__\\n\\nFor the transition period from\\n\\n__SEP__\\n\\nto\\n\\n__SEP__\\n\\nCommission File Number:\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\n(Exact name of Registrant as specified in its charter)\\n\\n__SEP__\\n\\nCalifornia\\n\\n__SEP__\\n\\n(State or other jurisdiction\\n\\n__SEP__\\n\\nof incorporation or organization)\\n\\n__SEP__\\n\\n(I.R.S. Employer Identification No.)\\n\\n__SEP__\\n\\nOne Apple Park Way\\n\\n__SEP__\\n\\nCupertino, California\\n\\n__SEP__\\n\\n(Address of principal executive offices)\\n\\n__SEP__\\n\\n(Zip Code)\\n\\n__SEP__\\n\\nSecurities registered pursuant to Section 12(b) of the Act:\\n\\n__SEP__\\n\\nTitle of each class\\n\\n__SEP__\\n\\nTrading symbol(s)\\n\\n__SEP__\\n\\nName of each exchange on which registered\\n\\n__SEP__\\n\\nCommon Stock, $0.00001 par value per share\\n\\n__SEP__\\n\\nAAPL\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n1.375% Notes due 2024\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n0.000% Notes due 2025\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n0.875% Notes due 2025\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n1.625% Notes due 2026\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n2.000% Notes due 2027\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n1.375% Notes due 2029\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n3.050% Notes due 2029\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n0.500% Notes due 2031\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\n3.600% Notes due 2042\\n\\n__SEP__\\n\\nThe Nasdaq Stock Market LLC\\n\\n__SEP__\\n\\nLarge accelerated filer\\n\\n__SEP__\\n\\nAccelerated filer\\n\\n__SEP__\\n\\nNon-accelerated filer\\n\\n__SEP__\\n\\nSmaller reporting company\\n\\n__SEP__\\n\\nEmerging growth company\\n\\n__SEP__\\n\\nIf an emerging growth company, indicate by check mark if the Registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act.\\n\\n__SEP__\\n\\nIndicate by check mark whether the Registrant is a shell company (as defined in Rule 12b-2 of the Exchange Act).\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\nForm 10-Q\\n\\n__SEP__\\n\\nTABLE OF CONTENTS\\n\\n__SEP__\\n\\nPage\\n\\n__SEP__\\n\\nPart I\\n\\n__SEP__\\n\\nItem 1.\\n\\n__SEP__\\n\\nFinancial Statements\\n\\n__SEP__\\n\\nItem 2.\\n\\n__SEP__\\n\\nItem 3.\\n\\n__SEP__\\n\\nQuantitative and Qualitative Disclosures About Market Risk\\n\\n__SEP__\\n\\nItem 4.\\n\\n__SEP__\\n\\nControls and Procedures\\n\\n__SEP__\\n\\nPart II\\n\\n__SEP__\\n\\nItem 1.\\n\\n__SEP__\\n\\nLegal Proceedings\\n\\n__SEP__\\n\\nItem 1A.\\n\\n__SEP__\\n\\nRisk Factors\\n\\n__SEP__\\n\\nItem 2.\\n\\n__SEP__\\n\\nUnregistered Sales of Equity Securities, Use of Proceeds, and Issuer Purchases of Equity Securities\\n\\n__SEP__\\n\\nItem 3.\\n\\n__SEP__\\n\\nDefaults Upon Senior Securities\\n\\n__SEP__\\n\\nItem 4.\\n\\n__SEP__\\n\\nMine Safety Disclosures\\n\\n__SEP__\\n\\nItem 5.\\n\\n__SEP__\\n\\nOther Information\\n\\n__SEP__\\n\\nItem 6.\\n\\n__SEP__\\n\\nExhibits\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\nCONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS (Unaudited)\\n\\n__SEP__\\n\\n(In millions, except number of shares which are reflected in thousands and per share amounts)\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nNet sales:\\n\\n__SEP__\\n\\nTotal net sales\\n\\n__SEP__\\n\\nCost of sales:\\n\\n__SEP__\\n\\nTotal cost of sales\\n\\n__SEP__\\n\\nGross margin\\n\\n__SEP__\\n\\nOperating expenses:\\n\\n__SEP__\\n\\nResearch and development\\n\\n__SEP__\\n\\nSelling, general and administrative\\n\\n__SEP__\\n\\nTotal operating expenses\\n\\n__SEP__\\n\\nOperating income\\n\\n__SEP__\\n\\nOther income/(expense), net\\n\\n__SEP__\\n\\nIncome before provision for income taxes\\n\\n__SEP__\\n\\nProvision for income taxes\\n\\n__SEP__\\n\\nNet income\\n\\n__SEP__\\n\\nEarnings per share:\\n\\n__SEP__\\n\\nBasic\\n\\n__SEP__\\n\\nDiluted\\n\\n__SEP__\\n\\nShares used in computing earnings per share:\\n\\n__SEP__\\n\\nBasic\\n\\n__SEP__\\n\\nDiluted\\n\\n__SEP__\\n\\nSee accompanying Notes to Condensed Consolidated Financial Statements.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 1\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\nCONDENSED CONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME (Unaudited)\\n\\n__SEP__\\n\\n(In millions)\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nNet income\\n\\n__SEP__\\n\\nOther comprehensive income/(loss):\\n\\n__SEP__\\n\\nChange in foreign currency translation, net of tax\\n\\n__SEP__\\n\\nChange in unrealized gains/losses on derivative instruments, net of tax:\\n\\n__SEP__\\n\\nChange in fair value of derivative instruments\\n\\n__SEP__\\n\\nAdjustment for net (gains)/losses realized and included in net income\\n\\n__SEP__\\n\\nTotal change in unrealized gains/losses on derivative instruments\\n\\n__SEP__\\n\\nChange in unrealized gains/losses on marketable debt securities, net of tax:\\n\\n__SEP__\\n\\nChange in fair value of marketable debt securities\\n\\n__SEP__\\n\\nAdjustment for net (gains)/losses realized and included in net income\\n\\n__SEP__\\n\\nTotal change in unrealized gains/losses on marketable debt securities\\n\\n__SEP__\\n\\nTotal other comprehensive income/(loss)\\n\\n__SEP__\\n\\nTotal comprehensive income\\n\\n__SEP__\\n\\nSee accompanying Notes to Condensed Consolidated Financial Statements.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 2\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\nCONDENSED CONSOLIDATED BALANCE SHEETS (Unaudited)\\n\\n__SEP__\\n\\n(In millions, except number of shares which are reflected in thousands and par value)\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nSeptember 24,\\n\\n__SEP__\\n\\nASSETS:\\n\\n__SEP__\\n\\nCurrent assets:\\n\\n__SEP__\\n\\nCash and cash equivalents\\n\\n__SEP__\\n\\nMarketable securities\\n\\n__SEP__\\n\\nAccounts receivable, net\\n\\n__SEP__\\n\\nInventories\\n\\n__SEP__\\n\\nVendor non-trade receivables\\n\\n__SEP__\\n\\nOther current assets\\n\\n__SEP__\\n\\nTotal current assets\\n\\n__SEP__\\n\\nNon-current assets:\\n\\n__SEP__\\n\\nMarketable securities\\n\\n__SEP__\\n\\nProperty, plant and equipment, net\\n\\n__SEP__\\n\\nOther non-current assets\\n\\n__SEP__\\n\\nTotal non-current assets\\n\\n__SEP__\\n\\nTotal assets\\n\\n__SEP__\\n\\nCurrent liabilities:\\n\\n__SEP__\\n\\nAccounts payable\\n\\n__SEP__\\n\\nOther current liabilities\\n\\n__SEP__\\n\\nDeferred revenue\\n\\n__SEP__\\n\\nCommercial paper\\n\\n__SEP__\\n\\nTerm debt\\n\\n__SEP__\\n\\nTotal current liabilities\\n\\n__SEP__\\n\\nNon-current liabilities:\\n\\n__SEP__\\n\\nTerm debt\\n\\n__SEP__\\n\\nOther non-current liabilities\\n\\n__SEP__\\n\\nTotal non-current liabilities\\n\\n__SEP__\\n\\nTotal liabilities\\n\\n__SEP__\\n\\nCommitments and contingencies\\n\\n__SEP__\\n\\nCommon stock and additional paid-in capital, $\\n\\n__SEP__\\n\\npar value:\\n\\n__SEP__\\n\\nshares authorized;\\n\\n__SEP__\\n\\nand\\n\\n__SEP__\\n\\nshares issued and outstanding, respectively\\n\\n__SEP__\\n\\nRetained earnings/(Accumulated deficit)\\n\\n__SEP__\\n\\nAccumulated other comprehensive income/(loss)\\n\\n__SEP__\\n\\nSee accompanying Notes to Condensed Consolidated Financial Statements.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 3\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\n(In millions, except per share amounts)\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nCommon stock and additional paid-in capital:\\n\\n__SEP__\\n\\nBeginning balances\\n\\n__SEP__\\n\\nCommon stock issued\\n\\n__SEP__\\n\\nCommon stock withheld related to net share settlement of equity awards\\n\\n__SEP__\\n\\nShare-based compensation\\n\\n__SEP__\\n\\nEnding balances\\n\\n__SEP__\\n\\nRetained earnings/(Accumulated deficit):\\n\\n__SEP__\\n\\nBeginning balances\\n\\n__SEP__\\n\\nNet income\\n\\n__SEP__\\n\\nDividends and dividend equivalents declared\\n\\n__SEP__\\n\\nCommon stock withheld related to net share settlement of equity awards\\n\\n__SEP__\\n\\nCommon stock repurchased\\n\\n__SEP__\\n\\nEnding balances\\n\\n__SEP__\\n\\nAccumulated other comprehensive income/(loss):\\n\\n__SEP__\\n\\nBeginning balances\\n\\n__SEP__\\n\\nOther comprehensive income/(loss)\\n\\n__SEP__\\n\\nEnding balances\\n\\n__SEP__\\n\\nDividends and dividend equivalents declared per share or RSU\\n\\n__SEP__\\n\\nSee accompanying Notes to Condensed Consolidated Financial Statements.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 4\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\nCONDENSED CONSOLIDATED STATEMENTS OF CASH FLOWS (Unaudited)\\n\\n__SEP__\\n\\n(In millions)\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nCash, cash equivalents and restricted cash, beginning balances\\n\\n__SEP__\\n\\nOperating activities:\\n\\n__SEP__\\n\\nNet income\\n\\n__SEP__\\n\\nAdjustments to reconcile net income to cash generated by operating activities:\\n\\n__SEP__\\n\\nDepreciation and amortization\\n\\n__SEP__\\n\\nShare-based compensation expense\\n\\n__SEP__\\n\\nOther\\n\\n__SEP__\\n\\nChanges in operating assets and liabilities:\\n\\n__SEP__\\n\\nAccounts receivable, net\\n\\n__SEP__\\n\\nInventories\\n\\n__SEP__\\n\\nVendor non-trade receivables\\n\\n__SEP__\\n\\nOther current and non-current assets\\n\\n__SEP__\\n\\nAccounts payable\\n\\n__SEP__\\n\\nOther current and non-current liabilities\\n\\n__SEP__\\n\\nCash generated by operating activities\\n\\n__SEP__\\n\\nInvesting activities:\\n\\n__SEP__\\n\\nPurchases of marketable securities\\n\\n__SEP__\\n\\nProceeds from maturities of marketable securities\\n\\n__SEP__\\n\\nProceeds from sales of marketable securities\\n\\n__SEP__\\n\\nPayments for acquisition of property, plant and equipment\\n\\n__SEP__\\n\\nOther\\n\\n__SEP__\\n\\nCash generated by/(used in) investing activities\\n\\n__SEP__\\n\\nFinancing activities:\\n\\n__SEP__\\n\\nPayments for taxes related to net share settlement of equity awards\\n\\n__SEP__\\n\\nPayments for dividends and dividend equivalents\\n\\n__SEP__\\n\\nRepurchases of common stock\\n\\n__SEP__\\n\\nProceeds from issuance of term debt, net\\n\\n__SEP__\\n\\nRepayments of term debt\\n\\n__SEP__\\n\\nProceeds from/(Repayments of) commercial paper, net\\n\\n__SEP__\\n\\nOther\\n\\n__SEP__\\n\\nCash used in financing activities\\n\\n__SEP__\\n\\nIncrease/(Decrease) in cash, cash equivalents and restricted cash\\n\\n__SEP__\\n\\nCash, cash equivalents and restricted cash, ending balances\\n\\n__SEP__\\n\\nSupplemental cash flow disclosure:\\n\\n__SEP__\\n\\nCash paid for income taxes, net\\n\\n__SEP__\\n\\nCash paid for interest\\n\\n__SEP__\\n\\nSee accompanying Notes to Condensed Consolidated Financial Statements.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 5\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\nNotes to Condensed Consolidated Financial Statements (Unaudited)\\n\\n__SEP__\\n\\nBasis of Presentation and Preparation\\n\\n__SEP__\\n\\nEarnings Per Share\\n\\n__SEP__\\n\\nThe following table shows the computation of basic and diluted earnings per share for the three- and nine-month periods ended July 1, 2023 and June 25, 2022 (net income in millions and shares in thousands):\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nNumerator:\\n\\n__SEP__\\n\\nNet income\\n\\n__SEP__\\n\\nDenominator:\\n\\n__SEP__\\n\\nWeighted-average basic shares outstanding\\n\\n__SEP__\\n\\nEffect of dilutive securities\\n\\n__SEP__\\n\\nWeighted-average diluted shares\\n\\n__SEP__\\n\\nBasic earnings per share\\n\\n__SEP__\\n\\nDiluted earnings per share\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 6\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\niPhone\\n\\n__SEP__\\n\\nMac\\n\\n__SEP__\\n\\niPad\\n\\n__SEP__\\n\\nWearables, Home and Accessories\\n\\n__SEP__\\n\\nServices\\n\\n__SEP__\\n\\nTotal net sales\\n\\n__SEP__\\n\\nCash, Cash Equivalents and Marketable Securities\\n\\n__SEP__\\n\\nJuly 1, 2023\\n\\n__SEP__\\n\\nAdjusted\\n\\n__SEP__\\n\\nCost\\n\\n__SEP__\\n\\nUnrealized\\n\\n__SEP__\\n\\nGains\\n\\n__SEP__\\n\\nUnrealized\\n\\n__SEP__\\n\\nLosses\\n\\n__SEP__\\n\\nFair\\n\\n__SEP__\\n\\nValue\\n\\n__SEP__\\n\\nCash and\\n\\n__SEP__\\n\\nCash\\n\\n__SEP__\\n\\nEquivalents\\n\\n__SEP__\\n\\nCurrent\\n\\n__SEP__\\n\\nMarketable\\n\\n__SEP__\\n\\nSecurities\\n\\n__SEP__\\n\\nNon-Current\\n\\n__SEP__\\n\\nMarketable\\n\\n__SEP__\\n\\nSecurities\\n\\n__SEP__\\n\\nCash\\n\\n__SEP__\\n\\nLevel 1\\n\\n__SEP__\\n\\nMoney market funds\\n\\n__SEP__\\n\\nMutual funds\\n\\n__SEP__\\n\\nSubtotal\\n\\n__SEP__\\n\\nLevel 2\\n\\n__SEP__\\n\\nU.S. Treasury securities\\n\\n__SEP__\\n\\nU.S. agency securities\\n\\n__SEP__\\n\\nNon-U.S. government securities\\n\\n__SEP__\\n\\nCertificates of deposit and time deposits\\n\\n__SEP__\\n\\nCommercial paper\\n\\n__SEP__\\n\\nCorporate debt securities\\n\\n__SEP__\\n\\nMunicipal securities\\n\\n__SEP__\\n\\nMortgage- and asset-backed securities\\n\\n__SEP__\\n\\nSubtotal\\n\\n__SEP__\\n\\nTotal\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 7\\n\\n__SEP__\\n\\nSeptember 24, 2022\\n\\n__SEP__\\n\\nAdjusted\\n\\n__SEP__\\n\\nCost\\n\\n__SEP__\\n\\nUnrealized\\n\\n__SEP__\\n\\nGains\\n\\n__SEP__\\n\\nUnrealized\\n\\n__SEP__\\n\\nLosses\\n\\n__SEP__\\n\\nFair\\n\\n__SEP__\\n\\nValue\\n\\n__SEP__\\n\\nCash and\\n\\n__SEP__\\n\\nCash\\n\\n__SEP__\\n\\nEquivalents\\n\\n__SEP__\\n\\nCurrent\\n\\n__SEP__\\n\\nMarketable\\n\\n__SEP__\\n\\nSecurities\\n\\n__SEP__\\n\\nNon-Current\\n\\n__SEP__\\n\\nMarketable\\n\\n__SEP__\\n\\nSecurities\\n\\n__SEP__\\n\\nCash\\n\\n__SEP__\\n\\nLevel 1\\n\\n__SEP__\\n\\nMoney market funds\\n\\n__SEP__\\n\\nMutual funds\\n\\n__SEP__\\n\\nSubtotal\\n\\n__SEP__\\n\\nLevel 2\\n\\n__SEP__\\n\\nU.S. Treasury securities\\n\\n__SEP__\\n\\nU.S. agency securities\\n\\n__SEP__\\n\\nNon-U.S. government securities\\n\\n__SEP__\\n\\nCertificates of deposit and time deposits\\n\\n__SEP__\\n\\nCommercial paper\\n\\n__SEP__\\n\\nCorporate debt securities\\n\\n__SEP__\\n\\nMunicipal securities\\n\\n__SEP__\\n\\nMortgage- and asset-backed securities\\n\\n__SEP__\\n\\nSubtotal\\n\\n__SEP__\\n\\nTotal\\n\\n__SEP__\\n\\nLevel 1 fair value estimates are based on quoted prices in active markets for identical assets or liabilities.\\n\\n__SEP__\\n\\nLevel 2 fair value estimates are based on observable inputs other than quoted prices in active markets for identical assets and liabilities, quoted prices for identical or similar assets or liabilities in inactive markets, or other inputs that are observable or can be corroborated by observable market data for substantially the full term of the assets or liabilities.\\n\\n__SEP__\\n\\nDue after 1 year through 5 years\\n\\n__SEP__\\n\\nDue after 5 years through 10 years\\n\\n__SEP__\\n\\nDue after 10 years\\n\\n__SEP__\\n\\nTotal fair value\\n\\n__SEP__\\n\\nDerivative Instruments and Hedging\\n\\n__SEP__\\n\\nThe Company may use derivative instruments to partially offset its business exposure to foreign exchange and interest rate risk. However, the Company may choose not to hedge certain exposures for a variety of reasons, including accounting considerations or the prohibitive economic cost of hedging particular exposures. There can be no assurance the hedges will offset more than a portion of the financial impact resulting from movements in foreign exchange or interest rates.\\n\\n__SEP__\\n\\nForeign Exchange Risk\\n\\n__SEP__\\n\\nTo protect gross margins from fluctuations in foreign currency exchange rates, the Company may enter into forward contracts, option contracts or other instruments, and may designate these instruments as cash flow hedges. The Company generally hedges portions of its forecasted foreign currency exposure associated with revenue and inventory purchases, typically for up to 12 months.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 8\\n\\n__SEP__\\n\\nThe Company may also enter into derivative instruments that are not designated as accounting hedges to protect gross margins from certain fluctuations in foreign currency exchange rates, as well as to offset a portion of the foreign currency exchange gains and losses generated by the remeasurement of certain assets and liabilities denominated in non-functional currencies.\\n\\n__SEP__\\n\\nInterest Rate Risk\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nSeptember 24,\\n\\n__SEP__\\n\\nDerivative instruments designated as accounting hedges:\\n\\n__SEP__\\n\\nForeign exchange contracts\\n\\n__SEP__\\n\\nInterest rate contracts\\n\\n__SEP__\\n\\nDerivative instruments not designated as accounting hedges:\\n\\n__SEP__\\n\\nForeign exchange contracts\\n\\n__SEP__\\n\\nSeptember 24, 2022\\n\\n__SEP__\\n\\nFair Value of\\n\\n__SEP__\\n\\nDerivatives Designated\\n\\n__SEP__\\n\\nas Accounting Hedges\\n\\n__SEP__\\n\\nFair Value of\\n\\n__SEP__\\n\\nDerivatives Not Designated\\n\\n__SEP__\\n\\nas Accounting Hedges\\n\\n__SEP__\\n\\nTotal\\n\\n__SEP__\\n\\nFair Value\\n\\n__SEP__\\n\\nDerivative assets\\n\\n__SEP__\\n\\nForeign exchange contracts\\n\\n__SEP__\\n\\nDerivative liabilities\\n\\n__SEP__\\n\\nForeign exchange contracts\\n\\n__SEP__\\n\\nInterest rate contracts\\n\\n__SEP__\\n\\nDerivative assets are measured using Level 2 fair value inputs and are included in other current assets and other non-current assets in the Condensed Consolidated Balance Sheet.\\n\\n__SEP__\\n\\nDerivative liabilities are measured using Level 2 fair value inputs and are included in other current liabilities and other non-current liabilities in the Condensed Consolidated Balance Sheet.\\n\\n__SEP__\\n\\nbillion, resulting in a net derivative asset of $412 million.\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nSeptember 24,\\n\\n__SEP__\\n\\nHedged assets/(liabilities):\\n\\n__SEP__\\n\\nCurrent and non-current marketable securities\\n\\n__SEP__\\n\\nCurrent and non-current term debt\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 9\\n\\n__SEP__\\n\\nAccounts Receivable\\n\\n__SEP__\\n\\nTrade Receivables\\n\\n__SEP__\\n\\nThe Company has considerable trade receivables outstanding with its third-party cellular network carriers, wholesalers, retailers, resellers, small and mid-sized businesses and education, enterprise and government customers. The Company generally does not require collateral from its customers; however, the Company will require collateral or third-party credit support in certain instances to limit credit risk. In addition, when possible, the Company attempts to limit credit risk on trade receivables with credit insurance for certain customers or by requiring third-party financing, loans or leases to support credit exposure. These credit-financing arrangements are directly between the third-party financing company and the end customer. As such, the Company generally does not assume any recourse or credit risk sharing related to any of these arrangements.\\n\\n__SEP__\\n\\nAs of\\n\\n__SEP__\\n\\n10%\\n\\n__SEP__\\n\\nVendor Non-Trade Receivables\\n\\n__SEP__\\n\\nInventories\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nSeptember 24,\\n\\n__SEP__\\n\\nComponents\\n\\n__SEP__\\n\\nFinished goods\\n\\n__SEP__\\n\\nTotal inventories\\n\\n__SEP__\\n\\nProperty, Plant and Equipment, Net\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nSeptember 24,\\n\\n__SEP__\\n\\nGross property, plant and equipment\\n\\n__SEP__\\n\\nAccumulated depreciation and amortization\\n\\n__SEP__\\n\\nTotal property, plant and equipment, net\\n\\n__SEP__\\n\\nOther Income/(Expense), Net\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nInterest and dividend income\\n\\n__SEP__\\n\\nInterest expense\\n\\n__SEP__\\n\\nOther expense, net\\n\\n__SEP__\\n\\nTotal other income/(expense), net\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 10\\n\\n__SEP__\\n\\nEuropean Commission State Aid Decision\\n\\n__SEP__\\n\\nCommercial Paper\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nMaturities 90 days or less:\\n\\n__SEP__\\n\\nProceeds from/(Repayments of) commercial paper, net\\n\\n__SEP__\\n\\nMaturities greater than 90 days:\\n\\n__SEP__\\n\\nProceeds from commercial paper\\n\\n__SEP__\\n\\nRepayments of commercial paper\\n\\n__SEP__\\n\\nProceeds from/(Repayments of) commercial paper, net\\n\\n__SEP__\\n\\nTotal proceeds from/(repayments of) commercial paper, net\\n\\n__SEP__\\n\\nTerm Debt\\n\\n__SEP__\\n\\n$95.3 billion and $98.8 billion, respectively.\\n\\n__SEP__\\n\\nShare Repurchase Program\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 11\\n\\n__SEP__\\n\\nRestricted Stock Units\\n\\n__SEP__\\n\\nNumber of\\n\\n__SEP__\\n\\nRSUs\\n\\n__SEP__\\n\\n(in thousands)\\n\\n__SEP__\\n\\nWeighted-Average\\n\\n__SEP__\\n\\nGrant Date Fair\\n\\n__SEP__\\n\\nValue Per RSU\\n\\n__SEP__\\n\\nAggregate\\n\\n__SEP__\\n\\nFair Value\\n\\n__SEP__\\n\\n(in millions)\\n\\n__SEP__\\n\\nBalance as of September 24, 2022\\n\\n__SEP__\\n\\nRSUs granted\\n\\n__SEP__\\n\\nRSUs vested\\n\\n__SEP__\\n\\nRSUs canceled\\n\\n__SEP__\\n\\nBalance as of July 1, 2023\\n\\n__SEP__\\n\\nThe fair value as of the respective vesting dates of RSUs was $7.0 billion and $14.9 billion for the three- and nine-month periods ended July 1, 2023, respectively, and was $7.8 billion and $17.3 billion for the three- and nine-month periods ended June 25, 2022, respectively.\\n\\n__SEP__\\n\\nShare-Based Compensation\\n\\n__SEP__\\n\\nThe following table shows share-based compensation expense and the related income tax benefit included in the Condensed Consolidated Statements of Operations for the three- and nine-month periods ended July 1, 2023 and June 25, 2022 (in millions):\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nShare-based compensation expense\\n\\n__SEP__\\n\\nIncome tax benefit related to share-based compensation expense\\n\\n__SEP__\\n\\nUnconditional Purchase Obligations\\n\\n__SEP__\\n\\n2023 (remaining three months)\\n\\n__SEP__\\n\\nThereafter\\n\\n__SEP__\\n\\nTotal\\n\\n__SEP__\\n\\nContingencies\\n\\n__SEP__\\n\\nThe Company is subject to various legal proceedings and claims that have arisen in the ordinary course of business and that have not been fully resolved. The outcome of litigation is inherently uncertain. In the opinion of management, there was not at least a reasonable possibility the Company may have incurred a material loss, or a material loss greater than a recorded accrual, concerning loss contingencies for asserted legal and other claims.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 12\\n\\n__SEP__\\n\\nThe following table shows information by reportable segment for the three- and nine-month periods ended July 1, 2023 and June 25, 2022 (in millions):\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nAmericas:\\n\\n__SEP__\\n\\nNet sales\\n\\n__SEP__\\n\\nOperating income\\n\\n__SEP__\\n\\nEurope:\\n\\n__SEP__\\n\\nNet sales\\n\\n__SEP__\\n\\nOperating income\\n\\n__SEP__\\n\\nGreater China:\\n\\n__SEP__\\n\\nNet sales\\n\\n__SEP__\\n\\nOperating income\\n\\n__SEP__\\n\\nJapan:\\n\\n__SEP__\\n\\nNet sales\\n\\n__SEP__\\n\\nOperating income\\n\\n__SEP__\\n\\nRest of Asia Pacific:\\n\\n__SEP__\\n\\nNet sales\\n\\n__SEP__\\n\\nOperating income\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nSegment operating income\\n\\n__SEP__\\n\\nResearch and development expense\\n\\n__SEP__\\n\\nOther corporate expenses, net\\n\\n__SEP__\\n\\nTotal operating income\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 13\\n\\n__SEP__\\n\\nAvailable Information\\n\\n__SEP__\\n\\nBusiness Seasonality and Product Introductions\\n\\n__SEP__\\n\\nFiscal Period\\n\\n__SEP__\\n\\nQuarterly Highlights\\n\\n__SEP__\\n\\nDuring the third quarter of 2023, the Company announced the following new products:\\n\\n__SEP__\\n\\n15-inch MacBook Air\\n\\n__SEP__\\n\\n, powered by the M2 chip;\\n\\n__SEP__\\n\\nMac Pro\\n\\n__SEP__\\n\\n, powered by the new M2 Ultra chip; and\\n\\n__SEP__\\n\\nThe Company also announced iOS 17, macOS\\n\\n__SEP__\\n\\nSonoma, iPadOS\\n\\n__SEP__\\n\\n17, tvOS\\n\\n__SEP__\\n\\n17 and watchOS\\n\\n__SEP__\\n\\n10, updates to its operating systems that are expected to be available in the fall of 2023.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 14\\n\\n__SEP__\\n\\nThe Company repurchased $18.0 billion of its common stock and paid dividends and dividend equivalents of $3.8 billion during the third quarter of 2023.\\n\\n__SEP__\\n\\nMacroeconomic Conditions\\n\\n__SEP__\\n\\nSegment Operating Performance\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nChange\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nChange\\n\\n__SEP__\\n\\nNet sales by reportable segment:\\n\\n__SEP__\\n\\nAmericas\\n\\n__SEP__\\n\\nEurope\\n\\n__SEP__\\n\\nGreater China\\n\\n__SEP__\\n\\nJapan\\n\\n__SEP__\\n\\nRest of Asia Pacific\\n\\n__SEP__\\n\\nTotal net sales\\n\\n__SEP__\\n\\nAmericas\\n\\n__SEP__\\n\\nAmericas net sales decreased during the third quarter and first nine months of 2023 compared to the same periods in 2022 due primarily to lower net sales of iPhone and Mac, partially offset by higher net sales of Services.\\n\\n__SEP__\\n\\nEurope\\n\\n__SEP__\\n\\nThe weakness in foreign currencies relative to the U.S. dollar had a net unfavorable year-over-year impact on Europe net sales during the third quarter and first nine months of 2023. During the third quarter of 2023, the Europe net sales increase consisted primarily of higher net sales of iPhone. During the first nine months of 2023, the Europe net sales decrease consisted primarily of lower net sales of Mac, partially offset by higher net sales of iPhone.\\n\\n__SEP__\\n\\nGreater China\\n\\n__SEP__\\n\\nThe weakness in the renminbi relative to the U.S. dollar had an unfavorable year-over-year impact on Greater China net sales during the third quarter and first nine months of 2023. During the third quarter of 2023, the Greater China net sales increase consisted primarily of higher net sales of iPhone. During the first nine months of 2023, the Greater China net sales decrease consisted primarily of lower net sales of iPhone.\\n\\n__SEP__\\n\\nJapan\\n\\n__SEP__\\n\\nThe weakness in the yen relative to the U.S. dollar had an unfavorable year-over-year impact on Japan net sales during the third quarter and first nine months of 2023. During the third quarter of 2023, the Japan net sales decrease consisted primarily of lower net sales of iPhone. During the first nine months of 2023, the Japan net sales decrease consisted primarily of lower net sales of iPhone, Services and Wearables, Home and Accessories.\\n\\n__SEP__\\n\\nRest of Asia Pacific\\n\\n__SEP__\\n\\nThe weakness in foreign currencies relative to the U.S. dollar had a net unfavorable year-over-year impact on Rest of Asia Pacific net sales during the third quarter and first nine months of 2023. During the third quarter of 2023, the Rest of Asia Pacific net sales decrease consisted primarily of lower net sales of iPhone and iPad. During the first nine months of 2023, the Rest of Asia Pacific net sales increase consisted primarily of higher net sales of iPhone, partially offset by lower net sales of Mac.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 15\\n\\n__SEP__\\n\\nProducts and Services Performance\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nChange\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nChange\\n\\n__SEP__\\n\\nNet sales by category:\\n\\n__SEP__\\n\\niPhone\\n\\n__SEP__\\n\\nMac\\n\\n__SEP__\\n\\niPad\\n\\n__SEP__\\n\\nWearables, Home and Accessories\\n\\n__SEP__\\n\\nServices\\n\\n__SEP__\\n\\nTotal net sales\\n\\n__SEP__\\n\\niPhone\\n\\n__SEP__\\n\\niPhone net sales decreased during the third quarter and first nine months of 2023 compared to the same periods in 2022 due primarily to lower net sales from certain iPhone models, partially offset by higher net sales of iPhone 14 Pro models.\\n\\n__SEP__\\n\\nMac\\n\\n__SEP__\\n\\nMac net sales decreased during the third quarter and first nine months of 2023 compared to the same periods in 2022 due primarily to lower net sales of laptops.\\n\\n__SEP__\\n\\niPad\\n\\n__SEP__\\n\\niPad net sales decreased during the third quarter of 2023 compared to the third quarter of 2022 due primarily to lower net sales across most iPad models. Year-over-year iPad net sales were relatively flat during the first nine months of 2023.\\n\\n__SEP__\\n\\nWearables, Home and Accessories\\n\\n__SEP__\\n\\nWearables, Home and Accessories net sales increased during the third quarter of 2023 compared to the third quarter of 2022 due primarily to higher net sales of Wearables, which includes AirPods\\n\\n__SEP__\\n\\n, Apple Watch\\n\\n__SEP__\\n\\nand Beats\\n\\n__SEP__\\n\\nproducts, partially offset by lower net sales of accessories. Year-over-year Wearables, Home and Accessories net sales decreased during the first nine months of 2023 due primarily to lower net sales of Wearables and accessories.\\n\\n__SEP__\\n\\nServices\\n\\n__SEP__\\n\\nServices net sales increased during the third quarter of 2023 compared to the third quarter of 2022 due primarily to higher net sales from advertising, cloud services and the App Store\\n\\n__SEP__\\n\\n. Year-over-year Services net sales increased during the first nine months of 2023 due primarily to higher net sales from cloud services, advertising and music.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 16\\n\\n__SEP__\\n\\nGross Margin\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nGross margin:\\n\\n__SEP__\\n\\nProducts\\n\\n__SEP__\\n\\nServices\\n\\n__SEP__\\n\\nTotal gross margin\\n\\n__SEP__\\n\\nGross margin percentage:\\n\\n__SEP__\\n\\nProducts\\n\\n__SEP__\\n\\nServices\\n\\n__SEP__\\n\\nTotal gross margin percentage\\n\\n__SEP__\\n\\nProducts Gross Margin\\n\\n__SEP__\\n\\nProducts gross margin decreased during the third quarter and first nine months of 2023 compared to the same periods in 2022 due primarily to the weakness in foreign currencies relative to the U.S. dollar and lower Products volume, partially offset by cost savings and a different Products mix.\\n\\n__SEP__\\n\\nProducts gross margin percentage increased during the third quarter of 2023 compared to the third quarter of 2022 due primarily to cost savings and a different Products mix, partially offset by the weakness in foreign currencies relative to the U.S. dollar and decreased leverage. Year-over-year Products gross margin percentage decreased during the first nine months of 2023 due primarily to the weakness in foreign currencies relative to the U.S. dollar and decreased leverage, partially offset by cost savings and a different Products mix.\\n\\n__SEP__\\n\\nServices Gross Margin\\n\\n__SEP__\\n\\nServices gross margin increased during the third quarter and first nine months of 2023 compared to the same periods in 2022 due primarily to higher Services net sales, partially offset by the weakness in foreign currencies relative to the U.S. dollar and higher Services costs.\\n\\n__SEP__\\n\\nServices gross margin percentage decreased during the third quarter of 2023 compared to the third quarter of 2022 due primarily to higher Services costs, partially offset by improved leverage. Year-over-year Services gross margin percentage decreased during the first nine months of 2023 due primarily to higher Services costs and the weakness in foreign currencies relative to the U.S. dollar, partially offset by improved leverage.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 17\\n\\n__SEP__\\n\\nOperating Expenses\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nResearch and development\\n\\n__SEP__\\n\\nPercentage of total net sales\\n\\n__SEP__\\n\\nSelling, general and administrative\\n\\n__SEP__\\n\\nPercentage of total net sales\\n\\n__SEP__\\n\\nTotal operating expenses\\n\\n__SEP__\\n\\nPercentage of total net sales\\n\\n__SEP__\\n\\nResearch and Development\\n\\n__SEP__\\n\\nSelling, General and Administrative\\n\\n__SEP__\\n\\nSelling, general and administrative expense was relatively flat during the third quarter and first nine months of 2023 compared to the same periods in 2022.\\n\\n__SEP__\\n\\nProvision for Income Taxes\\n\\n__SEP__\\n\\nThree Months Ended\\n\\n__SEP__\\n\\nNine Months Ended\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nJuly 1,\\n\\n__SEP__\\n\\nJune 25,\\n\\n__SEP__\\n\\nProvision for income taxes\\n\\n__SEP__\\n\\nEffective tax rate\\n\\n__SEP__\\n\\nStatutory federal income tax rate\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 18\\n\\n__SEP__\\n\\nLiquidity and Capital Resources\\n\\n__SEP__\\n\\nThe Company believes its balances of cash, cash equivalents and unrestricted marketable securities, along with cash generated by ongoing operations and continued access to debt markets, will be sufficient to satisfy its cash requirements and capital return program over the next 12 months and beyond.\\n\\n__SEP__\\n\\nManufacturing Purchase Obligations\\n\\n__SEP__\\n\\nCapital Return Program\\n\\n__SEP__\\n\\nCritical Accounting Estimates\\n\\n__SEP__\\n\\nEvaluation of Disclosure Controls and Procedures\\n\\n__SEP__\\n\\nChanges in Internal Control over Financial Reporting\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 19\\n\\n__SEP__\\n\\nEpic Games\\n\\n__SEP__\\n\\nOther Legal Proceedings\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 20\\n\\n__SEP__\\n\\nPurchases of Equity Securities by the Issuer and Affiliated Purchasers\\n\\n__SEP__\\n\\nPeriods\\n\\n__SEP__\\n\\nTotal Number\\n\\n__SEP__\\n\\nof Shares Purchased\\n\\n__SEP__\\n\\nAverage Price\\n\\n__SEP__\\n\\nPaid Per Share\\n\\n__SEP__\\n\\nTotal Number of Shares\\n\\n__SEP__\\n\\nPurchased as Part of Publicly\\n\\n__SEP__\\n\\nAnnounced Plans or Programs\\n\\n__SEP__\\n\\nApproximate Dollar Value of\\n\\n__SEP__\\n\\nShares That May Yet Be Purchased\\n\\n__SEP__\\n\\nUnder the Plans or Programs\\n\\n__SEP__\\n\\nApril 2, 2023 to May 6, 2023:\\n\\n__SEP__\\n\\nOpen market and privately negotiated purchases\\n\\n__SEP__\\n\\nMay 7, 2023 to June 3, 2023:\\n\\n__SEP__\\n\\nOpen market and privately negotiated purchases\\n\\n__SEP__\\n\\nJune 4, 2023 to July 1, 2023:\\n\\n__SEP__\\n\\nOpen market and privately negotiated purchases\\n\\n__SEP__\\n\\nTotal\\n\\n__SEP__\\n\\nNone.\\n\\n__SEP__\\n\\nNot applicable.\\n\\n__SEP__\\n\\nNone\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 21\\n\\n__SEP__\\n\\nIncorporated by Reference\\n\\n__SEP__\\n\\nExhibit\\n\\n__SEP__\\n\\nNumber\\n\\n__SEP__\\n\\nExhibit Description\\n\\n__SEP__\\n\\nForm\\n\\n__SEP__\\n\\nExhibit\\n\\n__SEP__\\n\\nFiling Date/\\n\\n__SEP__\\n\\nPeriod End Date\\n\\n__SEP__\\n\\nertificate of the Registrant, dated as of May 10, 2023, including forms of global notes representing the 4.421% Notes due 2026, 4.000% Notes due 2028, 4.150% Notes due 2030, 4.300% Notes due 2033 and 4.850% Notes due 2053.\\n\\n__SEP__\\n\\n8-K\\n\\n__SEP__\\n\\n5/10/23\\n\\n__SEP__\\n\\n31.1*\\n\\n__SEP__\\n\\nRule 13a-14(a) / 15d-14(a) Certification of Chief Executive Officer.\\n\\n__SEP__\\n\\n31.2*\\n\\n__SEP__\\n\\nRule 13a-14(a) / 15d-14(a) Certification of Chief Financial Officer.\\n\\n__SEP__\\n\\n32.1**\\n\\n__SEP__\\n\\nSection 1350 Certifications of Chief Executive Officer and Chief Financial Officer.\\n\\n__SEP__\\n\\n101*\\n\\n__SEP__\\n\\n104*\\n\\n__SEP__\\n\\nInline XBRL for the cover page of this Quarterly Report on Form 10-Q, included in the Exhibit 101 Inline XBRL Document Set.\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 22\\n\\n__SEP__\\n\\nSIGNATURE\\n\\n__SEP__\\n\\nPursuant to the requirements of the Securities Exchange Act of 1934, the Registrant has duly caused this report to be signed on its behalf by the undersigned thereunto duly authorized.\\n\\n__SEP__\\n\\nApple Inc.\\n\\n__SEP__\\n\\nBy:\\n\\n__SEP__\\n\\n/s/ Luca Maestri\\n\\n__SEP__\\n\\nLuca Maestri\\n\\n__SEP__\\n\\nSenior Vice President,\\n\\n__SEP__\\n\\nChief Financial Officer\\n\\n__SEP__\\n\\nApple Inc. | Q3 2023 Form 10-Q | 23'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f774fc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8818 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Your input_length: 8818 is bigger than 0.9 * max_length: 200. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    }
   ],
   "source": [
    "# 4. 한 번에 번역 실행\n",
    "translated_output = translator(\n",
    "    protected_text,\n",
    "    src_lang=\"en\",          # 또는 \"eng_Latn\"\n",
    "    tgt_lang=\"kor_Hang\",\n",
    "    do_sample=False,        # 결정론적\n",
    "    num_beams=4             # 번역 품질 향상\n",
    ")[0]['translation_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c95f2c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d43bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. 보호했던 구분자 복원 (__SEP__ → ␟)\n",
    "restored_output = translated_output.replace(\"__SEP__\", \"␟\")\n",
    "\n",
    "# 6. 번역된 결과 저장\n",
    "with open(\"data/translations/AAPL_2023_Q3_translated.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(restored_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66e7584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# 번역 파이프라인 준비\n",
    "translator = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebbe0a",
   "metadata": {},
   "source": [
    "다시해볼까 다시다시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0134eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# 1. 번역 파이프라인 & 토크나이저 준비\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "translator = pipeline(\"translation\", model=model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66390f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Your input_length: 1024 is bigger than 0.9 * max_length: 1024. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 9개의 청크로 분할됨\n",
      "\n",
      "🔄 청크 1/9 번역 중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🔄 청크 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 번역 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     translated \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkor_Hang\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📝 번역 결과 일부:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtranslated[:\u001b[38;5;241m300\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 앞 300자만 출력\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     translated_chunks\u001b[38;5;241m.\u001b[39mappend(translated)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:406\u001b[0m, in \u001b[0;36mTranslationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    377\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m          token ids of the translation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:187\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m    192\u001b[0m     ):\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\base.py:1464\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1457\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1458\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1461\u001b[0m         )\n\u001b[0;32m   1462\u001b[0m     )\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\base.py:1471\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1470\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1471\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1472\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\base.py:1371\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1370\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1371\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1372\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:216\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    214\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 216\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    217\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\generation\\utils.py:2644\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2637\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2638\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2639\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2640\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2641\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2642\u001b[0m     )\n\u001b[0;32m   2643\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2644\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2645\u001b[0m         input_ids,\n\u001b[0;32m   2646\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2647\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2648\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2649\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2650\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2651\u001b[0m     )\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2654\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2656\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2657\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\generation\\utils.py:4079\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   4076\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   4077\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m-> 4079\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   4081\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   4082\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   4083\u001b[0m     model_outputs,\n\u001b[0;32m   4084\u001b[0m     model_kwargs,\n\u001b[0;32m   4085\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   4086\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:1424\u001b[0m, in \u001b[0;36mM2M100ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1420\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1421\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1422\u001b[0m         )\n\u001b[1;32m-> 1424\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1442\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1444\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:1293\u001b[0m, in \u001b[0;36mM2M100Model.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1287\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1288\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1289\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1290\u001b[0m     )\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1293\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:1137\u001b[0m, in \u001b[0;36mM2M100Decoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1133\u001b[0m skip_the_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m (dropout_probability \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerdrop) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_the_layer \u001b[38;5;129;01mor\u001b[39;00m synced_gpus:\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;66;03m# under fsdp or deepspeed zero3 all gpus must run in sync\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\modeling_layers.py:83\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:478\u001b[0m, in \u001b[0;36mM2M100DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[0;32m    475\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_layer_norm(hidden_states)\n\u001b[0;32m    477\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m hidden_states, self_attn_weights, past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    487\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:333\u001b[0m, in \u001b[0;36mM2M100Attention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m attention_interface(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     query_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    332\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m--> 333\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights, past_key_value\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. 원본 텍스트 로드\n",
    "with open(\"data/segments/AAPL_2023_Q3_joined.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    original_text = f.read()\n",
    "\n",
    "# 3. 구분자 보호\n",
    "protected_text = original_text.replace(\"\\n\\n␟\\n\\n\", \"\\n\\n__SEP__\\n\\n\")\n",
    "\n",
    "# 4. 텍스트를 문장 단위로 분할 (간단하게 \\n 기준)\n",
    "lines = protected_text.split(\"\\n\")\n",
    "\n",
    "# 5. 문장을 모아서 1024 토큰 이하로 나눔\n",
    "chunks = []\n",
    "current_chunk = \"\"\n",
    "max_token = 1000\n",
    "\n",
    "for line in lines:\n",
    "    candidate = current_chunk + \"\\n\" + line if current_chunk else line\n",
    "    tokenized = tokenizer(candidate, return_tensors=\"pt\", truncation=False)\n",
    "    if tokenized[\"input_ids\"].shape[1] <= max_token:\n",
    "        current_chunk = candidate\n",
    "    else:\n",
    "        chunks.append(current_chunk)\n",
    "        current_chunk = line\n",
    "if current_chunk:\n",
    "    chunks.append(current_chunk)\n",
    "\n",
    "print(f\"✅ {len(chunks)}개의 청크로 분할됨\")\n",
    "\n",
    "# 6. 각 chunk 번역\n",
    "translated_chunks = []\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\n🔄 청크 {idx+1}/{len(chunks)} 번역 중...\")\n",
    "    translated = translator(\n",
    "        chunk,\n",
    "        src_lang=\"en\",\n",
    "        tgt_lang=\"kor_Hang\",\n",
    "        do_sample=False,\n",
    "        num_beams=4,\n",
    "        max_length=1024 \n",
    "    )[0]['translation_text']\n",
    "    print(f\"📝 번역 결과 일부:\\n{translated[:300]}...\\n\")  # 앞 300자만 출력\n",
    "    translated_chunks.append(translated)\n",
    "\n",
    "# 7. 구분자 복원\n",
    "final_output = \"\\n\".join(translated_chunks).replace(\"__SEP__\", \"␟\")\n",
    "\n",
    "# 8. 저장\n",
    "with open(\"data/translations/AAPL_2023_Q3_translated.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_output)\n",
    "\n",
    "print(\"\\n✅ 전체 번역 완료. 저장됨: data/translations/AAPL_2023_Q3_translated.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "355ddc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # HTML 파일 불러오기\n",
    "# # load original segments\n",
    "# with open(\"data/segments/AAPL_2023_Q3_joined.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     segments = f.read().split(\"\\n\\n␟\\n\\n\")\n",
    "\n",
    "# translations = []\n",
    "# for seg in segments:\n",
    "#     if seg.strip():\n",
    "#         result = translator(seg, src_lang=\"en\", tgt_lang=\"kor_Hang\",num_beams=2, penalty_alpha=0.6, top_k=4,)[0]['translation_text']\n",
    "#     else:\n",
    "#         result = \"\"\n",
    "#     translations.append(result)\n",
    "\n",
    "# # save to file\n",
    "# with open(\"data/translations/AAPL_2023_Q3_translated.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(\"\\n\\n␟\\n\\n\".join(translations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d08ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: value  \n",
    "# <eng>: korean\n",
    "translation_cache_table = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432f4b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APPL에서 APPL을 사용합니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = translator(\"APPL\", src_lang=\"en\", tgt_lang=\"kor_Hang\",num_beams=2, penalty_alpha=0.6, top_k=1, top_p=1, do_sample=True)[0]['translation_text']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd389e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aapl-20230701 1 미국 1 증권 및 거래소 위원회 1 워싱턴 DC 20549 1 양식 10-Q 1 (Marken One) 1 방정식 보고서 SECTION 13 또는 15에 관한 법률 1 또는 1 전환 보고서 1 또는 1934 SECURITIES EXCHANGE ACT의 SECTION 13 또는 15에 관한 법률 1 또는 1 전환 보고서 1 미국 증권 거래소 법 1934의 SECURITIES EXCHANGE ACT의 전환 기간 1 1에서 1 파일 번호: 1 애플 Inc. 1 (기본에 명시된 등록자의 정확한 이름) 1 캘리포니아 '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = translator('''\n",
    "aapl-20230701\n",
    "\n",
    "1\n",
    "\n",
    "UNITED STATES\n",
    "\n",
    "1\n",
    "\n",
    "SECURITIES AND EXCHANGE COMMISSION\n",
    "\n",
    "1\n",
    "\n",
    "Washington, D.C. 20549\n",
    "\n",
    "1\n",
    "\n",
    "FORM 10-Q\n",
    "\n",
    "1\n",
    "\n",
    "(Mark One)\n",
    "\n",
    "1\n",
    "\n",
    "QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
    "\n",
    "1\n",
    "\n",
    "or\n",
    "\n",
    "1\n",
    "\n",
    "TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
    "\n",
    "1\n",
    "\n",
    "For the transition period from\n",
    "\n",
    "1\n",
    "\n",
    "to\n",
    "\n",
    "1\n",
    "\n",
    "Commission File Number:\n",
    "\n",
    "1\n",
    "\n",
    "Apple Inc.\n",
    "\n",
    "1\n",
    "\n",
    "(Exact name of Registrant as specified in its charter)\n",
    "\n",
    "1\n",
    "\n",
    "California\n",
    "\n",
    "''', src_lang=\"en\", tgt_lang=\"kor_Hang\", \n",
    "num_beams=1,             \n",
    "penalty_alpha=None)[0]['translation_text']         \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09f34a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aapl-20230701  미국 증권 및 거래소위원회  워싱턴 DC 20549  FORM 10-Q  (Mark One)  SECURITIES EXCHANGE ACT OF 1934 '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16bc72",
   "metadata": {},
   "source": [
    "두번째태그달아서해보기시도\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6acd582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load and split by ␟\n",
    "with open(\"data/segments/AAPL_2023_Q3_joined.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    original = f.read()\n",
    "\n",
    "segments = original.strip().split(\"\\n\\n␟\\n\\n\")  # 구조 보존용\n",
    "tagged_segments = [f\"<SEG{i}>{seg}\" for i, seg in enumerate(segments)]\n",
    "tagged_text = \"\\n\".join(tagged_segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e88ac39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Your input_length: 10506 is bigger than 0.9 * max_length: 1024. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "translated_text = translator(\n",
    "    tagged_text,\n",
    "    src_lang=\"en\",\n",
    "    tgt_lang=\"kor_Hang\",\n",
    "    do_sample=False,\n",
    "    num_beams=4,\n",
    "    max_length=1024  # 필수!\n",
    ")[0][\"translation_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e0be3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] aapl-20230701 → <SEGSEGSEGSEGSEGSEGSEGSEGSEGSE\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 태그별로 추출 (예: <SEG0> ... <SEG1> ...)\n",
    "matches = re.split(r\"<SEG\\d+>\", translated_text)\n",
    "# 앞부분이 공백이거나 \"\"일 수 있으므로 제거\n",
    "translated_segments = [seg.strip() for seg in matches if seg.strip()]\n",
    "\n",
    "# 원래 순서 유지\n",
    "for i, (orig, trans) in enumerate(zip(segments, translated_segments)):\n",
    "    print(f\"[{i}] {orig[:30]} → {trans[:30]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2162e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/translations/AAPL_2023_Q3_translated_list.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for seg in translated_segments:\n",
    "        f.write(seg + \"\\n\\n␟\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a4acac",
   "metadata": {},
   "source": [
    "몰라 ==-----=====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbee3975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:16,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'aapl-20230701에 대한'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:17,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '미국에서는 물론이고, 미국에서는 물론이고, 미국에서도 마찬가지입니다.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:07<00:20,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'SECURITIES AND EXCHANGE COMMISSION (증권 및 거래소 위원회)'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:09<00:14,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '워싱턴 D.C. 20549에서'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:11<00:10,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'FORM 10-Q의 형태입니다.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:07,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '(Mark One에서)'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:16<00:07,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'SECURITIES EXCHANGE ACT OF 1934 제13조 또는 15조의 4차 보고서를 제출합니다.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:22<00:09,  3.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seg \u001b[38;5;129;01min\u001b[39;00m tqdm(segments[:\u001b[38;5;241m10\u001b[39m]):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m seg\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[1;32m----> 4\u001b[0m         trans_result \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkor_Hang\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpenalty_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m     \n\u001b[0;32m      7\u001b[0m         result \u001b[38;5;241m=\u001b[39m trans_result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(trans_result)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:406\u001b[0m, in \u001b[0;36mTranslationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    377\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m          token ids of the translation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:187\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m    192\u001b[0m     ):\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\base.py:1464\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1457\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1458\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1461\u001b[0m         )\n\u001b[0;32m   1462\u001b[0m     )\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\base.py:1471\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1470\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1471\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1472\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\base.py:1371\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1370\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1371\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1372\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:216\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    214\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 216\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    217\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\generation\\utils.py:2644\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2637\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2638\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2639\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2640\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2641\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2642\u001b[0m     )\n\u001b[0;32m   2643\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2644\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2645\u001b[0m         input_ids,\n\u001b[0;32m   2646\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2647\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2648\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2649\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2650\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2651\u001b[0m     )\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2654\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2656\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2657\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\generation\\utils.py:4079\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   4076\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   4077\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m-> 4079\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   4081\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   4082\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   4083\u001b[0m     model_outputs,\n\u001b[0;32m   4084\u001b[0m     model_kwargs,\n\u001b[0;32m   4085\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   4086\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:1442\u001b[0m, in \u001b[0;36mM2M100ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1420\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1421\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1422\u001b[0m         )\n\u001b[0;32m   1424\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1425\u001b[0m     input_ids,\n\u001b[0;32m   1426\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1441\u001b[0m )\n\u001b[1;32m-> 1442\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1444\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;66;03m# move labels to the correct device to enable PP\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\campus3S008\\Desktop\\Fomo\\caption-extension\\venv310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "translations = []\n",
    "for seg in tqdm(segments[:10]):\n",
    "    if seg.strip():\n",
    "        trans_result = translator(seg, src_lang=\"en\", tgt_lang=\"kor_Hang\", \n",
    "                    num_beams=5,             \n",
    "                    penalty_alpha=None)     \n",
    "        result = trans_result[0]['translation_text']\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        result = \"\"\n",
    "    translations.append(result)\n",
    "    \n",
    "dict(zip(segments[:10], translations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529bbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aapl-20230701': 'aapl-20230701에 대한 설명',\n",
       " 'UNITED STATES': '미국에서는 미군이',\n",
       " 'SECURITIES AND EXCHANGE COMMISSION': '증권 및 교환위원회',\n",
       " 'Washington, D.C. 20549': '워싱턴 D.C. 20549에 대한',\n",
       " 'FORM 10-Q': 'FORM 10-Q의 형태는',\n",
       " '(Mark One)': '(Mark One) (Mark One)',\n",
       " 'QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934': '13조 또는 15조에 따른 분기보고 (주) (d) 1934년 미국 증권거래법',\n",
       " 'or': '또는 오렌지',\n",
       " 'TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934': '13조 또는 15조에 의한 전환 보고서를 제출 (D) 1934년 미국 보안 거래소 법의',\n",
       " 'For the transition period from': '이 기간 동안은 전환 기간이'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44f97b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'미국에서는 미군이'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"UNITED STATES\", src_lang=\"en\", tgt_lang=\"kor_Hang\", \n",
    "                   do_sample=False,        # 샘플링 비활성화 → 핵심\n",
    "\n",
    "                    num_beams=1,   \n",
    "                    top_k = 1,\n",
    "                    top_p = 1 ,      \n",
    "                    penalty_alpha=None)[0]['translation_text']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ffb523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aapl-20230701에 대한 설명',\n",
       " '미국에서는 미군이',\n",
       " '증권 및 교환위원회',\n",
       " '워싱턴 D.C. 20549에 대한',\n",
       " 'FORM 10-Q의 형태는',\n",
       " '(Mark One) (Mark One)',\n",
       " '13조 또는 15조에 따른 분기보고 (주) (d) 1934년 미국 증권거래법',\n",
       " '또는 오렌지',\n",
       " '13조 또는 15조에 의한 전환 보고서를 제출 (D) 1934년 미국 보안 거래소 법의',\n",
       " '이 기간 동안은 전환 기간이']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a574e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HTML 파일 불러오기\n",
    "# load original segments\n",
    "with open(\"data/segments/AAPL_2023_Q3_joined.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    segments = f.read().split(\"\\n\\n␟\\n\\n\")\n",
    "\n",
    "translations = []\n",
    "for seg in segments:\n",
    "    if seg.strip():\n",
    "        result = translator(seg, src_lang=\"en\", tgt_lang=\"kor_Hang\",num_beams=2, penalty_alpha=0.6, top_k=4,)[0]['translation_text']\n",
    "    else:\n",
    "        result = \"\"\n",
    "    translations.append(result)\n",
    "\n",
    "# save to file\n",
    "with open(\"data/translations/AAPL_2023_Q3_translated.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n␟\\n\\n\".join(translations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162b9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 번역 실행\n",
    "# korean_text = translator(en, src_lang=\"en\", tgt_lang=\"kor_Hang\", num_beams=2, penalty_alpha=0.6, top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 결과 출력\n",
    "# print(korean_text[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # english_text = \"Hello, world! My name is AI.\"\n",
    "# korean_text = translator(english_text, src_lang=\"en\", tgt_lang=\"kor_Hang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en = \"\"\"amd-20231230\n",
    "\n",
    "# ␟\n",
    "\n",
    "# UNITED STATES SECURITIES AND EXCHANGE COMMISSION\n",
    "\n",
    "# ␟\n",
    "\n",
    "# Washington, D.C. 20549\n",
    "\n",
    "# ␟\n",
    "\n",
    "# FORM 10-K\n",
    "\n",
    "# ␟\n",
    "\n",
    "# (Mark One)\n",
    "\n",
    "# ␟\n",
    "\n",
    "# For the fiscal year ended\n",
    "\n",
    "# ␟\n",
    "\n",
    "# OR\n",
    "\n",
    "# ␟\n",
    "\n",
    "# For the transition period from\n",
    "\n",
    "# ␟\n",
    "\n",
    "# to\n",
    "\n",
    "# ␟\n",
    "\n",
    "# Commission File Number\n",
    "\n",
    "# ␟\n",
    "\n",
    "# ADVANCED MICRO DEVICES, INC.\n",
    "\n",
    "# ␟\n",
    "\n",
    "# (Exact name of registrant as specified in its charter)\n",
    "\n",
    "# ␟\n",
    "\n",
    "# Delaware\n",
    "\n",
    "# ␟\n",
    "\n",
    "# (State or other jurisdiction of incorporation or organization)\n",
    "\n",
    "# ␟\n",
    "\n",
    "# (I.R.S. Employer  Identification No.)\n",
    "\n",
    "# ␟\n",
    "\n",
    "# 2485 Augustine Drive\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ad37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# korean_text = translator(en, src_lang=\"en\", tgt_lang=\"kor_Hang\")\n",
    "# korean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# korean_text = translator(en, src_lang=\"en\", tgt_lang=\"kor_Hang\", num_beams=2, penalty_alpha=0.6, top_k=4, )\n",
    "# # korean_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
